## 本仓库是个人对基于深度学习的目标检测, 图像分类, 图像分割等领域相关模型的学习和复现。（仅个人学习使用）

### 一、目前已学习或复现的模型如下：

#### 1.轻量化网络：
- MobileNetV2 (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1801.04381v4)    
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/network)
- GhostConv + ResNet (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1801.04381v4)    
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/other_utils/conv)
- SCConv + ResNet/MobileNetV2 (已读论文, 已复现)  
    [论文地址](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_SCConv_Spatial_and_Channel_Reconstruction_Convolution_for_Feature_Redundancy_CVPR_2023_paper.pdf)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/other_utils/conv)
- EfficientNet (已读论文, 未复现)  
    [论文地址](https://arxiv.org/abs/1905.11946v5)  


#### 2.注意力机制的网络：
- SENet (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1709.01507v4)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/Attention)
- SKNet (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1903.06586)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/Attention)
- Coordinate Attention + MobileNetV2 (已读论文, 已复现)  
    [论文地址](https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.pdf)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/Attention)
- CPVT (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/2102.10882v3)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/Attention)
- MAE (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/2111.06377v2)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/Attention)
- ViT (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/2010.11929v2)    
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/image_classification)
- BoTNet (已读论文, 已复现)  
    [论文地址](https://openaccess.thecvf.com/content/CVPR2021/papers/Srinivas_Bottleneck_Transformers_for_Visual_Recognition_CVPR_2021_paper.pdf)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/network)
- CoTNet (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/2107.12292)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/network)
- Swin Transformer (已读论文, 未复现)  
    [论文地址](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf)  
- DETR (已读论文, 未复现)  
    [论文地址](https://arxiv.org/abs/2005.12872v3)  
- Deformable DETR (已读论文, 未复现, 已读源码)  
    [论文地址](https://openreview.net/pdf?id=gZ9hCDWe6ke)  


#### 3.动态卷积网络：
- CondConv + ResNet/MobileNetV2 (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1904.04971v3)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/network)
- ODConv + ResNet/MobileNetV2(已读论文, 已复现)  
    [论文地址](https://openreview.net/pdf?id=DmpCfq6Mg39)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/network)


#### 4.Yolo系列：
- YoloV1 (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1506.02640v5)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/object_detection)
- YoloV2 (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1612.08242v1)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/object_detection)
- YoloV3 (已读论文, 已复现)  
    [论文地址](https://arxiv.org/abs/1804.02767v1)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/object_detection)
- YoloV5 (未复现, 已读源码)  


#### 5.分割梯度流
- VoVNet(已复现OSA模块)
    [论文地址](https://arxiv.org/pdf/1904.09730v1.pdf)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/other_utils/conv)  
- CSPNet (已读论文, 已复现)
    [论文地址](https://arxiv.org/pdf/1911.11929v1.pdf)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/network)  


#### 6.其他CNN论文：
- DenseNet(已读论文, 已复现)
    [论文地址](https://arxiv.org/pdf/1608.06993v5.pdf)  
    [代码link](https://github.com/syz247179876/cv-deep-learning/tree/main/network)  

